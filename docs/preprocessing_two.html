<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Processing Geospatial Big Data with Delta Lake, Sparklyr, and Apache Sedona in R - 3&nbsp; Processing Vector Data with Apache Sedona and Sparklyr in R</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./preprocessing_three.html" rel="next">
<link href="./preprocessing_one.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./preprocessing_two.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Processing Vector Data with Apache Sedona and Sparklyr in R</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Processing Geospatial Big Data with Delta Lake, Sparklyr, and Apache Sedona in R</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/rog33zy/apache-sedona-r-tutorial.github.io" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preprocessing_one.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Preprocessing and Feature Engineering for Yellow Cab Trip Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preprocessing_two.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Processing Vector Data with Apache Sedona and Sparklyr in R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preprocessing_three.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Part One - Processing Raster Data with Apache Sedona and Sparklyr in R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preprocessing_four.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Part Two - Processing Raster Data with Apache Sedona and Sparklyr in R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preprocessing_five.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Combining Updated Locations Data with Initial Trip Data</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">3.1</span> Introduction</a></li>
  <li><a href="#installing-and-loading-packages" id="toc-installing-and-loading-packages" class="nav-link" data-scroll-target="#installing-and-loading-packages"><span class="header-section-number">3.2</span> Installing and loading packages</a></li>
  <li><a href="#configuring-spark" id="toc-configuring-spark" class="nav-link" data-scroll-target="#configuring-spark"><span class="header-section-number">3.3</span> Configuring Spark</a></li>
  <li><a href="#instantiating-spark-context" id="toc-instantiating-spark-context" class="nav-link" data-scroll-target="#instantiating-spark-context"><span class="header-section-number">3.4</span> Instantiating spark context</a></li>
  <li><a href="#loading-apache-sedona" id="toc-loading-apache-sedona" class="nav-link" data-scroll-target="#loading-apache-sedona"><span class="header-section-number">3.5</span> Loading Apache Sedona</a></li>
  <li><a href="#loading-datasets" id="toc-loading-datasets" class="nav-link" data-scroll-target="#loading-datasets"><span class="header-section-number">3.6</span> Loading datasets</a>
  <ul class="collapse">
  <li><a href="#locations-data" id="toc-locations-data" class="nav-link" data-scroll-target="#locations-data"><span class="header-section-number">3.6.1</span> Locations data</a></li>
  <li><a href="#median-household-income-by-neighbourhood-data" id="toc-median-household-income-by-neighbourhood-data" class="nav-link" data-scroll-target="#median-household-income-by-neighbourhood-data"><span class="header-section-number">3.6.2</span> Median household income by neighbourhood data</a></li>
  <li><a href="#nyc-neighbourhoods-data" id="toc-nyc-neighbourhoods-data" class="nav-link" data-scroll-target="#nyc-neighbourhoods-data"><span class="header-section-number">3.6.3</span> NYC neighbourhoods data</a></li>
  </ul></li>
  <li><a href="#associating-neighbourhood-with-median-household-income" id="toc-associating-neighbourhood-with-median-household-income" class="nav-link" data-scroll-target="#associating-neighbourhood-with-median-household-income"><span class="header-section-number">3.7</span> Associating neighbourhood with median household income</a></li>
  <li><a href="#joining-locations-data-with-neighbourhoods-data" id="toc-joining-locations-data-with-neighbourhoods-data" class="nav-link" data-scroll-target="#joining-locations-data-with-neighbourhoods-data"><span class="header-section-number">3.8</span> Joining locations data with neighbourhoods data</a></li>
  <li><a href="#writing-data-to-disk" id="toc-writing-data-to-disk" class="nav-link" data-scroll-target="#writing-data-to-disk"><span class="header-section-number">3.9</span> Writing data to disk</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/rog33zy/apache-sedona-r-tutorial.github.io/edit/main/preprocessing_two.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/rog33zy/apache-sedona-r-tutorial.github.io/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Processing Vector Data with Apache Sedona and Sparklyr in R</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">Using Vector Data to Obtain Median Household Income in Pickup and Droppoff Neighbourhoods</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">3.1</span> Introduction</h2>
<p>In this part, we are going to use the saved locations data to determine the <strong>pickup</strong> and <strong>dropoff neighbourhoods</strong> associated with each trip. We shall then use these additional data to obtain the <strong>median household incomes</strong> of the pickup and dropoff neighbourhoods. We use income as a proxy for <strong>affluence</strong>. Humour me by assuming that there is a relationship between the duration of a taxi trip and the affluence of either or both the pickup or dropoff locations.</p>
<p>We shall introduce two new datasets: <strong>NYC Neighbourhood Tabulation Areas (NTAs) boundaries</strong> based on the <a href="https://s-media.nyc.gov/agencies/dcp/assets/files/zip/data-tools/bytes/nynta2020_25a.zip">2020 census</a>, and <strong>NTA household median income</strong> based on the <a href="https://s-media.nyc.gov/agencies/dcp/assets/files/excel/data-tools/census/acs/Econ_1822_NTA.xlsx">2022 American Community Survey (ACS)</a>. The boundaries data is in <strong>vector format</strong>, while the income data is in <strong>CSV format</strong> (originally .xlsx but filtered for GeoID and MdHHIncE columns, then saved as CSV). To do this, we shall use <strong>Apache Sedona (v1.7.0)</strong> to merge the NTA boundaries and income data. We will then perform a <strong>spatial join</strong> on the coordinates with the boundaries, determining the pickup and dropoff neighbourhoods.</p>
<p>By the way, this will be a new file and not the same as the one used in Chapter 2. When working in local mode, I have found that it is more feasible to separate preprocessing into multiple stages. Running too many transformations at once is likely to result in out-of-memory errors and take a very long time to complete.</p>
</section>
<section id="installing-and-loading-packages" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="installing-and-loading-packages"><span class="header-section-number">3.2</span> Installing and loading packages</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"apache.sedona"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries for Spark, geospatial data, and data manipulation</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(arrow)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparklyr)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sf)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="configuring-spark" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="configuring-spark"><span class="header-section-number">3.3</span> Configuring Spark</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Spark directory for temporary files</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>spark_dir <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="fu">getwd</span>(), <span class="st">"data"</span>, <span class="st">"spark"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The configuration will mostly be kept similar to the one in the first file. The main difference is that some of the <strong>Delta configurations</strong> are explicitly included and not added as a package. This is because Delta and Apache Sedona clash when Delta is installed as a package when creating the Spark context.</p>
<p>You will notice a few differences in how the Spark context is set up this time around. Be sure to use this type of setup when working with Apache Sedona and reading or writing to Delta Lake.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an empty list for Spark configuration settings</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>config <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set Spark configurations for memory and performance optimisation</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure some delta specific options</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.sql.extensions <span class="ot">&lt;-</span> <span class="st">"io.delta.sql.DeltaSparkSessionExtension"</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.sql.catalog.spark_catalog <span class="ot">&lt;-</span> <span class="st">"org.apache.spark.sql.delta.catalog.DeltaCatalog"</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Use KryoSerializer for better performance</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.serializer <span class="ot">&lt;-</span> <span class="st">"org.apache.spark.serializer.KryoSerializer"</span>  </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Set temporary directory for Spark</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span><span class="st">`</span><span class="at">sparklyr.shell.driver-java-options</span><span class="st">`</span> <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"-Djava.io.tmpdir="</span>, spark_dir)  </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Use compressed Oops for JVM performance</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span><span class="st">`</span><span class="at">sparklyr.shell.driver-java-options</span><span class="st">`</span> <span class="ot">&lt;-</span> <span class="st">"-XX:+UseCompressedOops"</span>  </span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Allocate 8GB of memory for the Spark driver</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span><span class="st">`</span><span class="at">sparklyr.shell.driver-memory</span><span class="st">`</span> <span class="ot">&lt;-</span> <span class="st">'10G'</span>  </span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Set fraction of heap memory used for Spark storage</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.memory.fraction <span class="ot">&lt;-</span> <span class="fl">0.7</span>  </span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Set shuffle partitions (local setting based on workload)</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.sql.shuffle.partitions.local <span class="ot">&lt;-</span> <span class="dv">24</span>  </span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Set extra memory for driver</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.driver.extraJavaOptions <span class="ot">&lt;-</span> <span class="st">"-Xmx1G"</span>  </span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Enable off-heap memory usage</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.memory.offHeap.enabled <span class="ot">&lt;-</span> <span class="st">"true"</span> </span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Set 4GB for off-heap memory</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.memory.offHeap.size <span class="ot">&lt;-</span> <span class="st">"2g"</span>  </span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Disable shuffle spill to disk</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.sql.shuffle.spill <span class="ot">&lt;-</span> <span class="st">"false"</span>  </span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Periodic garbage collection interval</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.cleaner.periodicGC.interval <span class="ot">&lt;-</span> <span class="st">"60s"</span>  </span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Set max partition size for shuffle files</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.sql.files.maxPartitionBytes <span class="ot">&lt;-</span> <span class="st">"200m"</span>  </span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Enable adaptive query execution</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.sql.adaptive.enabled <span class="ot">&lt;-</span> <span class="st">"true"</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="instantiating-spark-context" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="instantiating-spark-context"><span class="header-section-number">3.4</span> Instantiating spark context</h2>
<p>As you can see, when initiating our Spark context, we explicitly include files associated with Delta and Apache Sedona. By doing so, Apache Sedona and Delta packages do not clash with each other.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Connect to Spark with the defined configuration and additional packages for geospatial processing</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">master =</span> <span class="st">"local[*]"</span>,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">config =</span> config,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">packages =</span> <span class="fu">c</span>(</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"io.delta:delta-spark_2.12:3.3.0"</span>,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"org.apache.sedona:sedona-spark-shaded-3.5_2.12:1.7.0"</span>,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"org.datasyslab:geotools-wrapper:1.7.0-28.5"</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="loading-apache-sedona" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="loading-apache-sedona"><span class="header-section-number">3.5</span> Loading Apache Sedona</h2>
<p>It is only after initializing our Spark context that we can now load the Apache Sedona library and initialize its context. We are now ready to get started!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(apache.sedona)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">invoke_static</span>(</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  sc,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">"org.apache.sedona.spark.SedonaContext"</span>,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"create"</span>,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">spark_session</span>(sc),</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">"r"</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;jobj[23]&gt;
  org.apache.spark.sql.SparkSession
  org.apache.spark.sql.SparkSession@12f7ff17</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Launch Spark web UI to monitor the Spark session</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_web</span>(sc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="loading-datasets" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="loading-datasets"><span class="header-section-number">3.6</span> Loading datasets</h2>
<section id="locations-data" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="locations-data"><span class="header-section-number">3.6.1</span> Locations data</h3>
<p>We now read our location data, which is thankfully in Delta Lake format.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the folder containing location data (latitude and longitude of yellow cabs)</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>locations_sdf_parent_folder <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="fu">getwd</span>(), <span class="st">"data"</span>, <span class="st">"locations_sdf"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>locations_sdf <span class="ot">&lt;-</span> <span class="fu">spark_read_delta</span>(</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  sc, </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">path =</span> locations_sdf_parent_folder, </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">name =</span> <span class="st">"locations_sdf"</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sdf_repartition</span>(<span class="dv">24</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(locations_sdf, <span class="at">width=</span><span class="cn">Inf</span>, <span class="at">n=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in arrow_collect(object, ...): NAs introduced by coercion to integer
range</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># Source:   table&lt;`sparklyr_tmp_edf5abab_3dd3_41c4_a79a_d6cd53ade301`&gt; [?? x 4]
# Database: spark_connection
    trip_id latitude longitude is_pickup
      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
 1 10626731     40.8     -74.0         1
 2  8962259     40.7     -74.0         1
 3  8129828     40.8     -74.0         1
 4  7977508     40.8     -74.0         1
 5  8775269     40.8     -73.9         1
 6  7608894     40.8     -74.0         1
 7  7466839     40.8     -74.0         1
 8  3762150     40.8     -74.0         1
 9 12333790     40.7     -74.0         1
10   562063     40.7     -74.0         1
# ℹ more rows</code></pre>
</div>
</div>
<p>The data contains nearly <strong>94 million rows</strong>!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the number of rows in the locations SDF (Spark DataFrame)</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sdf_nrow</span>(locations_sdf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 93889664</code></pre>
</div>
</div>
<p>And is partitioned equally for optimised wide transformations, especially joins. Wide transformations are those that require data shuffling (exchange) between multiple executors such as aggregations and joins. Meanwhile, narrow transformations do not require any exchange of data. Examples of narrow transformations include select and filter.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>locations_sdf <span class="sc">%&gt;%</span> <span class="fu">sdf_partition_sizes</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   partition_index partition_size
1                0        3912070
2                1        3912069
3                2        3912070
4                3        3912070
5                4        3912070
6                5        3912071
7                6        3912070
8                7        3912070
9                8        3912070
10               9        3912070
11              10        3912070
12              11        3912070
13              12        3912069
14              13        3912069
15              14        3912069
16              15        3912069
17              16        3912069
18              17        3912068
19              18        3912068
20              19        3912068
21              20        3912068
22              21        3912069
23              22        3912069
24              23        3912069</code></pre>
</div>
</div>
</section>
<section id="median-household-income-by-neighbourhood-data" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="median-household-income-by-neighbourhood-data"><span class="header-section-number">3.6.2</span> Median household income by neighbourhood data</h3>
<p>We now load the average household income by neighbourhood in NYC.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load income data (household income by NYC neighbourhood)</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>nyc_nta_hh_income_file_path <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="fu">getwd</span>(), <span class="st">"data"</span>, <span class="st">"nyc_nta_med_inc"</span>, <span class="st">"nyc_nta_med_inc.csv"</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>nyc_nta_hh_income <span class="ot">&lt;-</span> <span class="fu">spark_read_csv</span>(sc, <span class="at">path =</span> nyc_nta_hh_income_file_path, <span class="at">name =</span> <span class="st">"nyc_nta_hh_income"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the income data</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(nyc_nta_hh_income, <span class="at">width =</span> <span class="cn">Inf</span>, <span class="at">n=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in arrow_collect(object, ...): NAs introduced by coercion to integer
range</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># Source:   table&lt;`nyc_nta_hh_income`&gt; [?? x 2]
# Database: spark_connection
   GeoID  MdHHIncE
   &lt;chr&gt;     &lt;int&gt;
 1 BK0101   125469
 2 BK0102   129838
 3 BK0103    36951
 4 BK0104    71107
 5 BK0201   179877
 6 BK0202   149181
 7 BK0203   107633
 8 BK0204   115160
 9 BK0301    76660
10 BK0302    69954
# ℹ more rows</code></pre>
</div>
</div>
</section>
<section id="nyc-neighbourhoods-data" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="nyc-neighbourhoods-data"><span class="header-section-number">3.6.3</span> NYC neighbourhoods data</h3>
<p>We also load the shapefile using Apache Sedona. Note that we point Sedona to the entire folder and not just the specific .shp file, as is the case when reading shapefiles via sf.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the shapefile for NYC neighbourhoods</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>ny_neighs_pathfile <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="fu">getwd</span>(), <span class="st">"data"</span>, <span class="st">"shapefiles"</span>, <span class="st">"nynta2020_25a"</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>ny_neighbourhoods_shp <span class="ot">&lt;-</span> <span class="fu">spark_read_shapefile</span>(sc, <span class="at">path =</span> ny_neighs_pathfile, <span class="at">name =</span> <span class="st">"ny_neighbourhoods_shp"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: `spark_read_shapefile()` was deprecated in apache.sedona 1.7.1.
ℹ Please use `spark_read_source()` instead.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display a quick summary of the shapefile data</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>ny_neighbourhoods_shp <span class="sc">%&gt;%</span> <span class="fu">glimpse</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: ??</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in arrow_collect(object, ...): NAs introduced by coercion to integer
range</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Columns: 12
Database: spark_connection
$ geometry   &lt;arrw_bnr&gt; &lt;32, 00, 00, 00, db, 01, 00, 00, 00, 00, 90, fe, 67, 9…
$ BoroCode   &lt;chr&gt; "3", "3", "3", "3", "3", "3", "3", "3", "3", "3", "3", "3",…
$ BoroName   &lt;chr&gt; "Brooklyn", "Brooklyn", "Brooklyn", "Brooklyn", "Brooklyn",…
$ CountyFIPS &lt;chr&gt; "047", "047", "047", "047", "047", "047", "047", "047", "04…
$ NTA2020    &lt;chr&gt; "BK0101", "BK0102", "BK0103", "BK0104", "BK0201", "BK0202",…
$ NTAName    &lt;chr&gt; "Greenpoint", "Williamsburg", "South Williamsburg", "East W…
$ NTAAbbrev  &lt;chr&gt; "Grnpt", "Wllmsbrg", "SWllmsbrg", "EWllmsbrg", "BkHts", "Dw…
$ NTAType    &lt;chr&gt; "0", "0", "0", "0", "0", "0", "0", "0", "6", "0", "0", "0",…
$ CDTA2020   &lt;chr&gt; "BK01", "BK01", "BK01", "BK01", "BK02", "BK02", "BK02", "BK…
$ CDTAName   &lt;chr&gt; "BK01 Williamsburg-Greenpoint (CD 1 Equivalent)", "BK01 Wil…
$ Shape_Leng &lt;chr&gt; "2.89195621509e+04", "2.80980268049e+04", "1.82502803058e+0…
$ Shape_Area &lt;chr&gt; "3.53218095620e+07", "2.88543140796e+07", "1.52089606156e+0…</code></pre>
</div>
</div>
</section>
</section>
<section id="associating-neighbourhood-with-median-household-income" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="associating-neighbourhood-with-median-household-income"><span class="header-section-number">3.7</span> Associating neighbourhood with median household income</h2>
<p>We now join the income and boundaries data using their common ID.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Join the neighbourhood shapefile with the income data</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>ny_neighbourhoods_shp <span class="ot">&lt;-</span> ny_neighbourhoods_shp <span class="sc">%&gt;%</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(nyc_nta_hh_income, <span class="at">by =</span> <span class="fu">c</span>(<span class="st">"NTA2020"</span> <span class="ot">=</span> <span class="st">"GeoID"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we need to determine the relevant <strong>CRS</strong> that our shapefile uses. If it differs from <strong>EPSG:4326</strong>, we must convert it so that we can match it with the pickup and dropoff coordinates. I have not found a way to determine the CRS using Apache Sedona, so I use sf for that.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the shapefile as an SF (Simple Features) object for geospatial operations</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>ny_neighs_sf <span class="ot">&lt;-</span> <span class="fu">st_read</span>(<span class="fu">file.path</span>(ny_neighs_pathfile, <span class="st">"nynta2020.shp"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Reading layer `nynta2020' from data source 
  `/Users/rodgersiradukunda/Library/CloudStorage/OneDrive-TheUniversityofLiverpool/geospatial_docker/sedona-tutorial/data/shapefiles/nynta2020_25a/nynta2020.shp' 
  using driver `ESRI Shapefile'
Simple feature collection with 262 features and 11 fields
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: 913175.1 ymin: 120128.4 xmax: 1067383 ymax: 272844.3
Projected CRS: NAD83 / New York Long Island (ftUS)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">st_crs</span>(ny_neighs_sf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Coordinate Reference System:
  User input: NAD83 / New York Long Island (ftUS) 
  wkt:
PROJCRS["NAD83 / New York Long Island (ftUS)",
    BASEGEOGCRS["NAD83",
        DATUM["North American Datum 1983",
            ELLIPSOID["GRS 1980",6378137,298.257222101,
                LENGTHUNIT["metre",1]]],
        PRIMEM["Greenwich",0,
            ANGLEUNIT["degree",0.0174532925199433]],
        ID["EPSG",4269]],
    CONVERSION["SPCS83 New York Long Island zone (US survey foot)",
        METHOD["Lambert Conic Conformal (2SP)",
            ID["EPSG",9802]],
        PARAMETER["Latitude of false origin",40.1666666666667,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8821]],
        PARAMETER["Longitude of false origin",-74,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8822]],
        PARAMETER["Latitude of 1st standard parallel",41.0333333333333,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8823]],
        PARAMETER["Latitude of 2nd standard parallel",40.6666666666667,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8824]],
        PARAMETER["Easting at false origin",984250,
            LENGTHUNIT["US survey foot",0.304800609601219],
            ID["EPSG",8826]],
        PARAMETER["Northing at false origin",0,
            LENGTHUNIT["US survey foot",0.304800609601219],
            ID["EPSG",8827]]],
    CS[Cartesian,2],
        AXIS["easting (X)",east,
            ORDER[1],
            LENGTHUNIT["US survey foot",0.304800609601219]],
        AXIS["northing (Y)",north,
            ORDER[2],
            LENGTHUNIT["US survey foot",0.304800609601219]],
    USAGE[
        SCOPE["Engineering survey, topographic mapping."],
        AREA["United States (USA) - New York - counties of Bronx; Kings; Nassau; New York; Queens; Richmond; Suffolk."],
        BBOX[40.47,-74.26,41.3,-71.8]],
    ID["EPSG",2263]]</code></pre>
</div>
</div>
<p>Knowing that it is <strong>EPSG:2263</strong>, we can now convert it to <strong>EPSG:4326</strong>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reproject the geometries to a different coordinate reference system (CRS) for consistency</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>ny_neighbourhoods_shp <span class="ot">&lt;-</span> ny_neighbourhoods_shp <span class="sc">%&gt;%</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">geometry =</span> <span class="fu">st_transform</span>(</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>      geometry,</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>      <span class="st">"epsg:2263"</span>,  <span class="co"># Source CRS</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>      <span class="st">"epsg:4326"</span>,  <span class="co"># Target CRS</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>      F</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span><span class="fu">c</span>(</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>      BoroCode,</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>      CountyFIPS,</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>      NTAAbbrev,</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>      NTAType,</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>      CDTA2020,</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>      CDTAName,</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>      Shape_Leng,</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>      Shape_Area</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="joining-locations-data-with-neighbourhoods-data" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="joining-locations-data-with-neighbourhoods-data"><span class="header-section-number">3.8</span> Joining locations data with neighbourhoods data</h2>
<p>Because the boundaries data is very small (about 2 MB on disk), we can <strong>cache</strong> it in memory for faster access. Generally, you are encouraged to cache data that is less than <strong>10 MB</strong>. We are also <strong>broadcasting</strong> the neighbourhoods data to improve performance. Broadcasting means that our data is shared in its entirety with every executor so it is not shuffled when joining. This reduces data transfer overhead and improves performance.</p>
<p>Even if we did not explicitly broadcast our data, it most likely would have been broadcasted automatically due to <strong>Adaptive Query Execution</strong> (AQE) since we enabled it at the start using the option <code>config$spark.sql.adaptive.enabled &lt;- "true"</code>. AQE finds the optimal way of conducting joins, and since our neighbourhoods data is minuscule, chances are that it would have been broadcasted to prevent unnecessary shuffling.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Persist the neighbourhood shapefile in memory for faster access</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>ny_neighbourhoods_shp <span class="ot">&lt;-</span> <span class="fu">sdf_broadcast</span>(ny_neighbourhoods_shp)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sdf_persist</span>(ny_neighbourhoods_shp, <span class="at">storage.level =</span> <span class="st">"MEMORY_ONLY"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in arrow_collect(object, ...): NAs introduced by coercion to integer
range</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># Source:   table&lt;`sparklyr_tmp_ce3f2155_6fbf_4dad_b7a7_846178fd2db6`&gt; [?? x 5]
# Database: spark_connection
# ℹ more rows
# ℹ 5 more variables: geometry &lt;arrw_bnr&gt;, BoroName &lt;chr&gt;, NTA2020 &lt;chr&gt;,
#   NTAName &lt;chr&gt;, MdHHIncE &lt;int&gt;</code></pre>
</div>
</div>
<p>I have found that it is best to use <strong>Spatial SQL</strong> when conducting spatial joins or any other spatial analysis using Apache Sedona functions. To do this, we first need to register our dataframes as temporary <strong>SQL views</strong>. This will be our next step.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Register the dataframes as temporary SQL views for querying</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>locations_sdf <span class="sc">%&gt;%</span> <span class="fu">sdf_register</span>(<span class="st">"locations_sdf_view"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in arrow_collect(object, ...): NAs introduced by coercion to integer
range</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># Source:   table&lt;`locations_sdf_view`&gt; [?? x 4]
# Database: spark_connection
    trip_id latitude longitude is_pickup
      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
 1 40000037     40.7     -74.0         0
 2 40000093     40.7     -74.0         0
 3 40000016     40.8     -74.0         0
 4 40000091     40.8     -74.0         0
 5 40000100     40.8     -74.0         1
 6 40000031     40.8     -74.0         1
 7 40000044     40.8     -74.0         1
 8 40000015     40.8     -74.0         1
 9 40000005     40.7     -74.0         0
10 40000053     40.8     -74.0         0
# ℹ more rows</code></pre>
</div>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>ny_neighbourhoods_shp <span class="sc">%&gt;%</span> <span class="fu">sdf_register</span>(<span class="st">"ny_neighbourhoods_shp_view"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in arrow_collect(object, ...): NAs introduced by coercion to integer
range</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># Source:   table&lt;`ny_neighbourhoods_shp_view`&gt; [?? x 5]
# Database: spark_connection
# ℹ more rows
# ℹ 5 more variables: geometry &lt;arrw_bnr&gt;, BoroName &lt;chr&gt;, NTA2020 &lt;chr&gt;,
#   NTAName &lt;chr&gt;, MdHHIncE &lt;int&gt;</code></pre>
</div>
</div>
<p>Upon registration, we can now conduct a spatial join, asking Apache Sedona to find neighbourhoods that contain specific coordinates using the <strong>ST_Contains</strong> function. You can find documentation on all available Apache Sedona vector functions <a href="https://sedona.apache.org/latest/api/sql/Function/">here</a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a spatial join to associate each location (latitude, longitude) with the corresponding neighbourhood</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>locations_sdf_updated <span class="ot">&lt;-</span> <span class="fu">sdf_sql</span>(</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>  sc,</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">"</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="st">  SELECT /*+ BROADCAST(b) */ a.*, b.*</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="st">  FROM locations_sdf_view a</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="st">  LEFT JOIN ny_neighbourhoods_shp_view b</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="st">    ON ST_Contains(b.geometry, ST_Point(a.longitude, a.latitude))</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="st">  "</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="writing-data-to-disk" class="level2" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="writing-data-to-disk"><span class="header-section-number">3.9</span> Writing data to disk</h2>
<p>Before saving our updated data, we remove the geometry column, as Delta Lake does not support geometry columns. Moreover, there is no need to keep it in the data, as we don’t plan on mapping the data just yet. If you need to write big data geometry files, consider using the <strong>GeoParquet</strong> format. You can do so using Spark’s <code>spark_write_geoparquet</code> function or the <code>spark_write_source</code> function with the mode set to “<em>geoparquet</em>”.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the geometry column from the final dataset for further analysis</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>locations_sdf_updated_no_geom <span class="ot">&lt;-</span> locations_sdf_updated <span class="sc">%&gt;%</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(geometry))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Our final data is as shown below. Not too bad for the few lines of code written.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the updated data with all relevant fields (no geometry)</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>withr<span class="sc">::</span><span class="fu">with_options</span>(</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="at">pillar.sigfig =</span> <span class="dv">6</span>),</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(locations_sdf_updated_no_geom, <span class="at">n=</span><span class="dv">10</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in arrow_collect(object, ...): NAs introduced by coercion to integer
range</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># Source:   SQL [?? x 8]
# Database: spark_connection
    trip_id latitude longitude is_pickup BoroName  NTA2020 NTAName      MdHHIncE
      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;           &lt;int&gt;
 1 40000037  40.7113  -74.0107         0 Manhattan MN0101  Financial D…   195153
 2 40000093  40.7401  -73.9860         0 Manhattan MN0602  Gramercy       155905
 3 40000016  40.8148  -73.9553         0 Manhattan MN0902  Manhattanvi…    46367
 4 40000091  40.7743  -73.9614         0 Manhattan MN0802  Upper East …   194910
 5 40000100  40.7604  -73.9614         1 Manhattan MN0801  Upper East …   133349
 6 40000031  40.7794  -73.9849         1 Manhattan MN0701  Upper West …   158165
 7 40000044  40.7633  -73.9594         1 Manhattan MN0801  Upper East …   133349
 8 40000015  40.7776  -73.9551         1 Manhattan MN0802  Upper East …   194910
 9 40000005  40.7419  -73.9746         0 Manhattan MN0603  Murray Hill…   138337
10 40000053  40.7765  -73.9767         0 Manhattan MN0701  Upper West …   158165
# ℹ more rows</code></pre>
</div>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>locations_sdf_updated_no_geom <span class="sc">%&gt;%</span> <span class="fu">glimpse</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: ??</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in arrow_collect(object, ...): NAs introduced by coercion to integer
range</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Columns: 8
Database: spark_connection
$ trip_id   &lt;dbl&gt; 40000037, 40000093, 40000016, 40000091, 40000100, 40000031, …
$ latitude  &lt;dbl&gt; 40.71130, 40.74007, 40.81481, 40.77428, 40.76038, 40.77941, …
$ longitude &lt;dbl&gt; -74.01067, -73.98603, -73.95528, -73.96144, -73.96136, -73.9…
$ is_pickup &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, …
$ BoroName  &lt;chr&gt; "Manhattan", "Manhattan", "Manhattan", "Manhattan", "Manhatt…
$ NTA2020   &lt;chr&gt; "MN0101", "MN0602", "MN0902", "MN0802", "MN0801", "MN0701", …
$ NTAName   &lt;chr&gt; "Financial District-Battery Park City", "Gramercy", "Manhatt…
$ MdHHIncE  &lt;int&gt; 195153, 155905, 46367, 194910, 133349, 158165, 133349, 19491…</code></pre>
</div>
</div>
<p>We now write our data to Delta Lake format as usual.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the file path for saving the updated dataset</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>save_locations_sdf_updated_one_filepath <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="fu">getwd</span>(), <span class="st">"data"</span>, <span class="st">"locations_sdf_updated_one"</span>)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the updated dataset to Delta format</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_write_delta</span>(</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>  locations_sdf_updated_no_geom,</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">path =</span> save_locations_sdf_updated_one_filepath</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And disconnect our spark instance.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Disconnect from the Spark session once done</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_disconnect</span>(sc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./preprocessing_one.html" class="pagination-link  aria-label=" &lt;span="" and="" feature="" engineering="" for="" yellow="" cab="" trip="" data&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Preprocessing and Feature Engineering for Yellow Cab Trip Data</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./preprocessing_three.html" class="pagination-link" aria-label="<span class='chapter-number'>4</span>&nbsp; <span class='chapter-title'>Part One - Processing Raster Data with Apache Sedona and Sparklyr in R</span>">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Part One - Processing Raster Data with Apache Sedona and Sparklyr in R</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb52" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Processing Vector Data with Apache Sedona and Sparklyr in R"</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Using Vector Data to Obtain Median Household Income in Pickup and Droppoff Neighbourhoods"</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span><span class="co"> </span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="co">  eval: true</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="co">  output: true</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>In this part, we are going to use the saved locations data to determine the **pickup** and **dropoff neighbourhoods** associated with each trip. We shall then use these additional data to obtain the **median household incomes** of the pickup and dropoff neighbourhoods. We use income as a proxy for **affluence**. Humour me by assuming that there is a relationship between the duration of a taxi trip and the affluence of either or both the pickup or dropoff locations.</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>We shall introduce two new datasets: **NYC Neighbourhood Tabulation Areas (NTAs) boundaries** based on the [2020 census](https://s-media.nyc.gov/agencies/dcp/assets/files/zip/data-tools/bytes/nynta2020_25a.zip), and **NTA household median income** based on the [2022 American Community Survey (ACS)](https://s-media.nyc.gov/agencies/dcp/assets/files/excel/data-tools/census/acs/Econ_1822_NTA.xlsx). The boundaries data is in **vector format**, while the income data is in **CSV format** (originally .xlsx but filtered for GeoID and MdHHIncE columns, then saved as CSV). To do this, we shall use **Apache Sedona (v1.7.0)** to merge the NTA boundaries and income data. We will then perform a **spatial join** on the coordinates with the boundaries, determining the pickup and dropoff neighbourhoods.</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>By the way, this will be a new file and not the same as the one used in Chapter 2. When working in local mode, I have found that it is more feasible to separate preprocessing into multiple stages. Running too many transformations at once is likely to result in out-of-memory errors and take a very long time to complete.</span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a><span class="fu">## Installing and loading packages</span></span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"apache.sedona"</span>)</span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-30"><a href="#cb52-30" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb52-31"><a href="#cb52-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-32"><a href="#cb52-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries for Spark, geospatial data, and data manipulation</span></span>
<span id="cb52-33"><a href="#cb52-33" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(arrow)</span>
<span id="cb52-34"><a href="#cb52-34" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparklyr)</span>
<span id="cb52-35"><a href="#cb52-35" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sf)</span>
<span id="cb52-36"><a href="#cb52-36" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb52-37"><a href="#cb52-37" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-38"><a href="#cb52-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-41"><a href="#cb52-41" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-42"><a href="#cb52-42" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb52-43"><a href="#cb52-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-44"><a href="#cb52-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Install Spark version 3.5.5 if not already installed</span></span>
<span id="cb52-45"><a href="#cb52-45" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_install</span>(<span class="st">"3.5.5"</span>)</span>
<span id="cb52-46"><a href="#cb52-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-47"><a href="#cb52-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up Java and Spark environment variables</span></span>
<span id="cb52-48"><a href="#cb52-48" aria-hidden="true" tabindex="-1"></a><span class="fu">Sys.setenv</span>(<span class="st">"JAVA_HOME"</span><span class="ot">=</span><span class="st">"/Library/Java/JavaVirtualMachines/zulu-11.jdk/Contents/Home"</span>)  <span class="co"># Set Java home directory for Spark</span></span>
<span id="cb52-49"><a href="#cb52-49" aria-hidden="true" tabindex="-1"></a><span class="fu">Sys.setenv</span>(<span class="st">"SPARK_HOME"</span> <span class="ot">=</span> <span class="fu">spark_home_dir</span>(<span class="at">version =</span> <span class="st">"3.5.5"</span>))</span>
<span id="cb52-50"><a href="#cb52-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-51"><a href="#cb52-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Set working directory to the location of your project</span></span>
<span id="cb52-52"><a href="#cb52-52" aria-hidden="true" tabindex="-1"></a>working_dir <span class="ot">&lt;-</span> <span class="st">"/Users/rodgersiradukunda/Library/CloudStorage/OneDrive-TheUniversityofLiverpool/geospatial_docker"</span></span>
<span id="cb52-53"><a href="#cb52-53" aria-hidden="true" tabindex="-1"></a><span class="fu">setwd</span>(working_dir)</span>
<span id="cb52-54"><a href="#cb52-54" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-55"><a href="#cb52-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-56"><a href="#cb52-56" aria-hidden="true" tabindex="-1"></a><span class="fu">## Configuring Spark</span></span>
<span id="cb52-57"><a href="#cb52-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-60"><a href="#cb52-60" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-61"><a href="#cb52-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Spark directory for temporary files</span></span>
<span id="cb52-62"><a href="#cb52-62" aria-hidden="true" tabindex="-1"></a>spark_dir <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="fu">getwd</span>(), <span class="st">"data"</span>, <span class="st">"spark"</span>)</span>
<span id="cb52-63"><a href="#cb52-63" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-64"><a href="#cb52-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-65"><a href="#cb52-65" aria-hidden="true" tabindex="-1"></a>The configuration will mostly be kept similar to the one in the first file. The main difference is that some of the **Delta configurations** are explicitly included and not added as a package. This is because Delta and Apache Sedona clash when Delta is installed as a package when creating the Spark context.</span>
<span id="cb52-66"><a href="#cb52-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-67"><a href="#cb52-67" aria-hidden="true" tabindex="-1"></a>You will notice a few differences in how the Spark context is set up this time around. Be sure to use this type of setup when working with Apache Sedona and reading or writing to Delta Lake.</span>
<span id="cb52-68"><a href="#cb52-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-71"><a href="#cb52-71" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-72"><a href="#cb52-72" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an empty list for Spark configuration settings</span></span>
<span id="cb52-73"><a href="#cb52-73" aria-hidden="true" tabindex="-1"></a>config <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb52-74"><a href="#cb52-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-75"><a href="#cb52-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Set Spark configurations for memory and performance optimisation</span></span>
<span id="cb52-76"><a href="#cb52-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-77"><a href="#cb52-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure some delta specific options</span></span>
<span id="cb52-78"><a href="#cb52-78" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.sql.extensions <span class="ot">&lt;-</span> <span class="st">"io.delta.sql.DeltaSparkSessionExtension"</span></span>
<span id="cb52-79"><a href="#cb52-79" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.sql.catalog.spark_catalog <span class="ot">&lt;-</span> <span class="st">"org.apache.spark.sql.delta.catalog.DeltaCatalog"</span></span>
<span id="cb52-80"><a href="#cb52-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-81"><a href="#cb52-81" aria-hidden="true" tabindex="-1"></a><span class="co"># Use KryoSerializer for better performance</span></span>
<span id="cb52-82"><a href="#cb52-82" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.serializer <span class="ot">&lt;-</span> <span class="st">"org.apache.spark.serializer.KryoSerializer"</span>  </span>
<span id="cb52-83"><a href="#cb52-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-84"><a href="#cb52-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Set temporary directory for Spark</span></span>
<span id="cb52-85"><a href="#cb52-85" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span><span class="st">`</span><span class="at">sparklyr.shell.driver-java-options</span><span class="st">`</span> <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"-Djava.io.tmpdir="</span>, spark_dir)  </span>
<span id="cb52-86"><a href="#cb52-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-87"><a href="#cb52-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Use compressed Oops for JVM performance</span></span>
<span id="cb52-88"><a href="#cb52-88" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span><span class="st">`</span><span class="at">sparklyr.shell.driver-java-options</span><span class="st">`</span> <span class="ot">&lt;-</span> <span class="st">"-XX:+UseCompressedOops"</span>  </span>
<span id="cb52-89"><a href="#cb52-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-90"><a href="#cb52-90" aria-hidden="true" tabindex="-1"></a><span class="co"># Allocate 8GB of memory for the Spark driver</span></span>
<span id="cb52-91"><a href="#cb52-91" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span><span class="st">`</span><span class="at">sparklyr.shell.driver-memory</span><span class="st">`</span> <span class="ot">&lt;-</span> <span class="st">'10G'</span>  </span>
<span id="cb52-92"><a href="#cb52-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-93"><a href="#cb52-93" aria-hidden="true" tabindex="-1"></a><span class="co"># Set fraction of heap memory used for Spark storage</span></span>
<span id="cb52-94"><a href="#cb52-94" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.memory.fraction <span class="ot">&lt;-</span> <span class="fl">0.7</span>  </span>
<span id="cb52-95"><a href="#cb52-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-96"><a href="#cb52-96" aria-hidden="true" tabindex="-1"></a><span class="co"># Set shuffle partitions (local setting based on workload)</span></span>
<span id="cb52-97"><a href="#cb52-97" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.sql.shuffle.partitions.local <span class="ot">&lt;-</span> <span class="dv">24</span>  </span>
<span id="cb52-98"><a href="#cb52-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-99"><a href="#cb52-99" aria-hidden="true" tabindex="-1"></a><span class="co"># Set extra memory for driver</span></span>
<span id="cb52-100"><a href="#cb52-100" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.driver.extraJavaOptions <span class="ot">&lt;-</span> <span class="st">"-Xmx1G"</span>  </span>
<span id="cb52-101"><a href="#cb52-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-102"><a href="#cb52-102" aria-hidden="true" tabindex="-1"></a><span class="co"># Enable off-heap memory usage</span></span>
<span id="cb52-103"><a href="#cb52-103" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.memory.offHeap.enabled <span class="ot">&lt;-</span> <span class="st">"true"</span> </span>
<span id="cb52-104"><a href="#cb52-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-105"><a href="#cb52-105" aria-hidden="true" tabindex="-1"></a><span class="co"># Set 4GB for off-heap memory</span></span>
<span id="cb52-106"><a href="#cb52-106" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.memory.offHeap.size <span class="ot">&lt;-</span> <span class="st">"2g"</span>  </span>
<span id="cb52-107"><a href="#cb52-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-108"><a href="#cb52-108" aria-hidden="true" tabindex="-1"></a><span class="co"># Disable shuffle spill to disk</span></span>
<span id="cb52-109"><a href="#cb52-109" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.sql.shuffle.spill <span class="ot">&lt;-</span> <span class="st">"false"</span>  </span>
<span id="cb52-110"><a href="#cb52-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-111"><a href="#cb52-111" aria-hidden="true" tabindex="-1"></a><span class="co"># Periodic garbage collection interval</span></span>
<span id="cb52-112"><a href="#cb52-112" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.cleaner.periodicGC.interval <span class="ot">&lt;-</span> <span class="st">"60s"</span>  </span>
<span id="cb52-113"><a href="#cb52-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-114"><a href="#cb52-114" aria-hidden="true" tabindex="-1"></a><span class="co"># Set max partition size for shuffle files</span></span>
<span id="cb52-115"><a href="#cb52-115" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.sql.files.maxPartitionBytes <span class="ot">&lt;-</span> <span class="st">"200m"</span>  </span>
<span id="cb52-116"><a href="#cb52-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-117"><a href="#cb52-117" aria-hidden="true" tabindex="-1"></a><span class="co"># Enable adaptive query execution</span></span>
<span id="cb52-118"><a href="#cb52-118" aria-hidden="true" tabindex="-1"></a>config<span class="sc">$</span>spark.sql.adaptive.enabled <span class="ot">&lt;-</span> <span class="st">"true"</span> </span>
<span id="cb52-119"><a href="#cb52-119" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-120"><a href="#cb52-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-121"><a href="#cb52-121" aria-hidden="true" tabindex="-1"></a><span class="fu">## Instantiating spark context</span></span>
<span id="cb52-122"><a href="#cb52-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-123"><a href="#cb52-123" aria-hidden="true" tabindex="-1"></a>As you can see, when initiating our Spark context, we explicitly include files associated with Delta and Apache Sedona. By doing so, Apache Sedona and Delta packages do not clash with each other.</span>
<span id="cb52-124"><a href="#cb52-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-127"><a href="#cb52-127" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-128"><a href="#cb52-128" aria-hidden="true" tabindex="-1"></a><span class="co"># Connect to Spark with the defined configuration and additional packages for geospatial processing</span></span>
<span id="cb52-129"><a href="#cb52-129" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(</span>
<span id="cb52-130"><a href="#cb52-130" aria-hidden="true" tabindex="-1"></a>  <span class="at">master =</span> <span class="st">"local[*]"</span>,</span>
<span id="cb52-131"><a href="#cb52-131" aria-hidden="true" tabindex="-1"></a>  <span class="at">config =</span> config,</span>
<span id="cb52-132"><a href="#cb52-132" aria-hidden="true" tabindex="-1"></a>  <span class="at">packages =</span> <span class="fu">c</span>(</span>
<span id="cb52-133"><a href="#cb52-133" aria-hidden="true" tabindex="-1"></a>    <span class="st">"io.delta:delta-spark_2.12:3.3.0"</span>,</span>
<span id="cb52-134"><a href="#cb52-134" aria-hidden="true" tabindex="-1"></a>    <span class="st">"org.apache.sedona:sedona-spark-shaded-3.5_2.12:1.7.0"</span>,</span>
<span id="cb52-135"><a href="#cb52-135" aria-hidden="true" tabindex="-1"></a>    <span class="st">"org.datasyslab:geotools-wrapper:1.7.0-28.5"</span></span>
<span id="cb52-136"><a href="#cb52-136" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb52-137"><a href="#cb52-137" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb52-138"><a href="#cb52-138" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-139"><a href="#cb52-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-140"><a href="#cb52-140" aria-hidden="true" tabindex="-1"></a><span class="fu">## Loading Apache Sedona</span></span>
<span id="cb52-141"><a href="#cb52-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-142"><a href="#cb52-142" aria-hidden="true" tabindex="-1"></a>It is only after initializing our Spark context that we can now load the Apache Sedona library and initialize its context. We are now ready to get started!</span>
<span id="cb52-143"><a href="#cb52-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-146"><a href="#cb52-146" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-147"><a href="#cb52-147" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(apache.sedona)</span>
<span id="cb52-148"><a href="#cb52-148" aria-hidden="true" tabindex="-1"></a><span class="fu">invoke_static</span>(</span>
<span id="cb52-149"><a href="#cb52-149" aria-hidden="true" tabindex="-1"></a>  sc,</span>
<span id="cb52-150"><a href="#cb52-150" aria-hidden="true" tabindex="-1"></a>  <span class="st">"org.apache.sedona.spark.SedonaContext"</span>,</span>
<span id="cb52-151"><a href="#cb52-151" aria-hidden="true" tabindex="-1"></a>  <span class="st">"create"</span>,</span>
<span id="cb52-152"><a href="#cb52-152" aria-hidden="true" tabindex="-1"></a>  <span class="fu">spark_session</span>(sc),</span>
<span id="cb52-153"><a href="#cb52-153" aria-hidden="true" tabindex="-1"></a>  <span class="st">"r"</span></span>
<span id="cb52-154"><a href="#cb52-154" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb52-155"><a href="#cb52-155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-156"><a href="#cb52-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-159"><a href="#cb52-159" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-160"><a href="#cb52-160" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb52-161"><a href="#cb52-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-162"><a href="#cb52-162" aria-hidden="true" tabindex="-1"></a><span class="co"># Launch Spark web UI to monitor the Spark session</span></span>
<span id="cb52-163"><a href="#cb52-163" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_web</span>(sc)</span>
<span id="cb52-164"><a href="#cb52-164" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-165"><a href="#cb52-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-166"><a href="#cb52-166" aria-hidden="true" tabindex="-1"></a><span class="fu">## Loading datasets</span></span>
<span id="cb52-167"><a href="#cb52-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-168"><a href="#cb52-168" aria-hidden="true" tabindex="-1"></a><span class="fu">### Locations data</span></span>
<span id="cb52-169"><a href="#cb52-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-170"><a href="#cb52-170" aria-hidden="true" tabindex="-1"></a>We now read our location data, which is thankfully in Delta Lake format.</span>
<span id="cb52-171"><a href="#cb52-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-174"><a href="#cb52-174" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-175"><a href="#cb52-175" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the folder containing location data (latitude and longitude of yellow cabs)</span></span>
<span id="cb52-176"><a href="#cb52-176" aria-hidden="true" tabindex="-1"></a>locations_sdf_parent_folder <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="fu">getwd</span>(), <span class="st">"data"</span>, <span class="st">"locations_sdf"</span>)</span>
<span id="cb52-177"><a href="#cb52-177" aria-hidden="true" tabindex="-1"></a>locations_sdf <span class="ot">&lt;-</span> <span class="fu">spark_read_delta</span>(</span>
<span id="cb52-178"><a href="#cb52-178" aria-hidden="true" tabindex="-1"></a>  sc, </span>
<span id="cb52-179"><a href="#cb52-179" aria-hidden="true" tabindex="-1"></a>  <span class="at">path =</span> locations_sdf_parent_folder, </span>
<span id="cb52-180"><a href="#cb52-180" aria-hidden="true" tabindex="-1"></a>  <span class="at">name =</span> <span class="st">"locations_sdf"</span></span>
<span id="cb52-181"><a href="#cb52-181" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb52-182"><a href="#cb52-182" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sdf_repartition</span>(<span class="dv">24</span>)</span>
<span id="cb52-183"><a href="#cb52-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-184"><a href="#cb52-184" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(locations_sdf, <span class="at">width=</span><span class="cn">Inf</span>, <span class="at">n=</span><span class="dv">10</span>)</span>
<span id="cb52-185"><a href="#cb52-185" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-186"><a href="#cb52-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-187"><a href="#cb52-187" aria-hidden="true" tabindex="-1"></a>The data contains nearly **94 million rows**!</span>
<span id="cb52-188"><a href="#cb52-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-191"><a href="#cb52-191" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-192"><a href="#cb52-192" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the number of rows in the locations SDF (Spark DataFrame)</span></span>
<span id="cb52-193"><a href="#cb52-193" aria-hidden="true" tabindex="-1"></a><span class="fu">sdf_nrow</span>(locations_sdf)</span>
<span id="cb52-194"><a href="#cb52-194" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-195"><a href="#cb52-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-196"><a href="#cb52-196" aria-hidden="true" tabindex="-1"></a>And is partitioned equally for optimised wide transformations, especially joins. Wide transformations are those that require data shuffling (exchange) between multiple executors such as aggregations and joins. Meanwhile, narrow transformations do not require any exchange of data. Examples of narrow transformations include select and filter.</span>
<span id="cb52-197"><a href="#cb52-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-200"><a href="#cb52-200" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-201"><a href="#cb52-201" aria-hidden="true" tabindex="-1"></a>locations_sdf <span class="sc">%&gt;%</span> <span class="fu">sdf_partition_sizes</span>()</span>
<span id="cb52-202"><a href="#cb52-202" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-203"><a href="#cb52-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-206"><a href="#cb52-206" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-207"><a href="#cb52-207" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb52-208"><a href="#cb52-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-209"><a href="#cb52-209" aria-hidden="true" tabindex="-1"></a>locations_sdf <span class="ot">&lt;-</span> locations_sdf <span class="sc">%&gt;%</span> </span>
<span id="cb52-210"><a href="#cb52-210" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(trip_id <span class="sc">&gt;=</span> <span class="dv">40000000</span> <span class="sc">&amp;</span> trip_id <span class="sc">&lt;=</span> <span class="dv">40000100</span>)</span>
<span id="cb52-211"><a href="#cb52-211" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-212"><a href="#cb52-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-213"><a href="#cb52-213" aria-hidden="true" tabindex="-1"></a><span class="fu">### Median household income by neighbourhood data</span></span>
<span id="cb52-214"><a href="#cb52-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-215"><a href="#cb52-215" aria-hidden="true" tabindex="-1"></a>We now load the average household income by neighbourhood in NYC.</span>
<span id="cb52-216"><a href="#cb52-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-219"><a href="#cb52-219" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-220"><a href="#cb52-220" aria-hidden="true" tabindex="-1"></a><span class="co"># Load income data (household income by NYC neighbourhood)</span></span>
<span id="cb52-221"><a href="#cb52-221" aria-hidden="true" tabindex="-1"></a>nyc_nta_hh_income_file_path <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="fu">getwd</span>(), <span class="st">"data"</span>, <span class="st">"nyc_nta_med_inc"</span>, <span class="st">"nyc_nta_med_inc.csv"</span>)</span>
<span id="cb52-222"><a href="#cb52-222" aria-hidden="true" tabindex="-1"></a>nyc_nta_hh_income <span class="ot">&lt;-</span> <span class="fu">spark_read_csv</span>(sc, <span class="at">path =</span> nyc_nta_hh_income_file_path, <span class="at">name =</span> <span class="st">"nyc_nta_hh_income"</span>)</span>
<span id="cb52-223"><a href="#cb52-223" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-224"><a href="#cb52-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-227"><a href="#cb52-227" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-228"><a href="#cb52-228" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the income data</span></span>
<span id="cb52-229"><a href="#cb52-229" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(nyc_nta_hh_income, <span class="at">width =</span> <span class="cn">Inf</span>, <span class="at">n=</span><span class="dv">10</span>)</span>
<span id="cb52-230"><a href="#cb52-230" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-231"><a href="#cb52-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-232"><a href="#cb52-232" aria-hidden="true" tabindex="-1"></a><span class="fu">### NYC neighbourhoods data</span></span>
<span id="cb52-233"><a href="#cb52-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-234"><a href="#cb52-234" aria-hidden="true" tabindex="-1"></a>We also load the shapefile using Apache Sedona. Note that we point Sedona to the entire folder and not just the specific .shp file, as is the case when reading shapefiles via sf.</span>
<span id="cb52-235"><a href="#cb52-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-238"><a href="#cb52-238" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-239"><a href="#cb52-239" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the shapefile for NYC neighbourhoods</span></span>
<span id="cb52-240"><a href="#cb52-240" aria-hidden="true" tabindex="-1"></a>ny_neighs_pathfile <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="fu">getwd</span>(), <span class="st">"data"</span>, <span class="st">"shapefiles"</span>, <span class="st">"nynta2020_25a"</span>)</span>
<span id="cb52-241"><a href="#cb52-241" aria-hidden="true" tabindex="-1"></a>ny_neighbourhoods_shp <span class="ot">&lt;-</span> <span class="fu">spark_read_shapefile</span>(sc, <span class="at">path =</span> ny_neighs_pathfile, <span class="at">name =</span> <span class="st">"ny_neighbourhoods_shp"</span>)</span>
<span id="cb52-242"><a href="#cb52-242" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-243"><a href="#cb52-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-246"><a href="#cb52-246" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-247"><a href="#cb52-247" aria-hidden="true" tabindex="-1"></a><span class="co"># Display a quick summary of the shapefile data</span></span>
<span id="cb52-248"><a href="#cb52-248" aria-hidden="true" tabindex="-1"></a>ny_neighbourhoods_shp <span class="sc">%&gt;%</span> <span class="fu">glimpse</span>()</span>
<span id="cb52-249"><a href="#cb52-249" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-250"><a href="#cb52-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-251"><a href="#cb52-251" aria-hidden="true" tabindex="-1"></a><span class="fu">## Associating neighbourhood with median household income</span></span>
<span id="cb52-252"><a href="#cb52-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-253"><a href="#cb52-253" aria-hidden="true" tabindex="-1"></a>We now join the income and boundaries data using their common ID.</span>
<span id="cb52-254"><a href="#cb52-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-257"><a href="#cb52-257" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-258"><a href="#cb52-258" aria-hidden="true" tabindex="-1"></a><span class="co"># Join the neighbourhood shapefile with the income data</span></span>
<span id="cb52-259"><a href="#cb52-259" aria-hidden="true" tabindex="-1"></a>ny_neighbourhoods_shp <span class="ot">&lt;-</span> ny_neighbourhoods_shp <span class="sc">%&gt;%</span></span>
<span id="cb52-260"><a href="#cb52-260" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(nyc_nta_hh_income, <span class="at">by =</span> <span class="fu">c</span>(<span class="st">"NTA2020"</span> <span class="ot">=</span> <span class="st">"GeoID"</span>))</span>
<span id="cb52-261"><a href="#cb52-261" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-262"><a href="#cb52-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-263"><a href="#cb52-263" aria-hidden="true" tabindex="-1"></a>Now, we need to determine the relevant **CRS** that our shapefile uses. If it differs from **EPSG:4326**, we must convert it so that we can match it with the pickup and dropoff coordinates. I have not found a way to determine the CRS using Apache Sedona, so I use sf for that.</span>
<span id="cb52-264"><a href="#cb52-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-267"><a href="#cb52-267" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-268"><a href="#cb52-268" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the shapefile as an SF (Simple Features) object for geospatial operations</span></span>
<span id="cb52-269"><a href="#cb52-269" aria-hidden="true" tabindex="-1"></a>ny_neighs_sf <span class="ot">&lt;-</span> <span class="fu">st_read</span>(<span class="fu">file.path</span>(ny_neighs_pathfile, <span class="st">"nynta2020.shp"</span>))</span>
<span id="cb52-270"><a href="#cb52-270" aria-hidden="true" tabindex="-1"></a><span class="fu">st_crs</span>(ny_neighs_sf)</span>
<span id="cb52-271"><a href="#cb52-271" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-272"><a href="#cb52-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-273"><a href="#cb52-273" aria-hidden="true" tabindex="-1"></a>Knowing that it is **EPSG:2263**, we can now convert it to **EPSG:4326**.</span>
<span id="cb52-274"><a href="#cb52-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-277"><a href="#cb52-277" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-278"><a href="#cb52-278" aria-hidden="true" tabindex="-1"></a><span class="co"># Reproject the geometries to a different coordinate reference system (CRS) for consistency</span></span>
<span id="cb52-279"><a href="#cb52-279" aria-hidden="true" tabindex="-1"></a>ny_neighbourhoods_shp <span class="ot">&lt;-</span> ny_neighbourhoods_shp <span class="sc">%&gt;%</span></span>
<span id="cb52-280"><a href="#cb52-280" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb52-281"><a href="#cb52-281" aria-hidden="true" tabindex="-1"></a>    <span class="at">geometry =</span> <span class="fu">st_transform</span>(</span>
<span id="cb52-282"><a href="#cb52-282" aria-hidden="true" tabindex="-1"></a>      geometry,</span>
<span id="cb52-283"><a href="#cb52-283" aria-hidden="true" tabindex="-1"></a>      <span class="st">"epsg:2263"</span>,  <span class="co"># Source CRS</span></span>
<span id="cb52-284"><a href="#cb52-284" aria-hidden="true" tabindex="-1"></a>      <span class="st">"epsg:4326"</span>,  <span class="co"># Target CRS</span></span>
<span id="cb52-285"><a href="#cb52-285" aria-hidden="true" tabindex="-1"></a>      F</span>
<span id="cb52-286"><a href="#cb52-286" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb52-287"><a href="#cb52-287" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb52-288"><a href="#cb52-288" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(</span>
<span id="cb52-289"><a href="#cb52-289" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span><span class="fu">c</span>(</span>
<span id="cb52-290"><a href="#cb52-290" aria-hidden="true" tabindex="-1"></a>      BoroCode,</span>
<span id="cb52-291"><a href="#cb52-291" aria-hidden="true" tabindex="-1"></a>      CountyFIPS,</span>
<span id="cb52-292"><a href="#cb52-292" aria-hidden="true" tabindex="-1"></a>      NTAAbbrev,</span>
<span id="cb52-293"><a href="#cb52-293" aria-hidden="true" tabindex="-1"></a>      NTAType,</span>
<span id="cb52-294"><a href="#cb52-294" aria-hidden="true" tabindex="-1"></a>      CDTA2020,</span>
<span id="cb52-295"><a href="#cb52-295" aria-hidden="true" tabindex="-1"></a>      CDTAName,</span>
<span id="cb52-296"><a href="#cb52-296" aria-hidden="true" tabindex="-1"></a>      Shape_Leng,</span>
<span id="cb52-297"><a href="#cb52-297" aria-hidden="true" tabindex="-1"></a>      Shape_Area</span>
<span id="cb52-298"><a href="#cb52-298" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb52-299"><a href="#cb52-299" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb52-300"><a href="#cb52-300" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-301"><a href="#cb52-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-302"><a href="#cb52-302" aria-hidden="true" tabindex="-1"></a><span class="fu">## Joining locations data with neighbourhoods data</span></span>
<span id="cb52-303"><a href="#cb52-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-304"><a href="#cb52-304" aria-hidden="true" tabindex="-1"></a>Because the boundaries data is very small (about 2 MB on disk), we can **cache** it in memory for faster access. Generally, you are encouraged to cache data that is less than **10 MB**. We are also **broadcasting** the neighbourhoods data to improve performance. Broadcasting means that our data is shared in its entirety with every executor so it is not shuffled when joining. This reduces data transfer overhead and improves performance. </span>
<span id="cb52-305"><a href="#cb52-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-306"><a href="#cb52-306" aria-hidden="true" tabindex="-1"></a>Even if we did not explicitly broadcast our data, it most likely would have been broadcasted automatically due to **Adaptive Query Execution** (AQE) since we enabled it at the start using the option <span class="in">`config$spark.sql.adaptive.enabled &lt;- "true"`</span>. AQE finds the optimal way of conducting joins, and since our neighbourhoods data is minuscule, chances are that it would have been broadcasted to prevent unnecessary shuffling.</span>
<span id="cb52-307"><a href="#cb52-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-310"><a href="#cb52-310" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-311"><a href="#cb52-311" aria-hidden="true" tabindex="-1"></a><span class="co"># Persist the neighbourhood shapefile in memory for faster access</span></span>
<span id="cb52-312"><a href="#cb52-312" aria-hidden="true" tabindex="-1"></a>ny_neighbourhoods_shp <span class="ot">&lt;-</span> <span class="fu">sdf_broadcast</span>(ny_neighbourhoods_shp)</span>
<span id="cb52-313"><a href="#cb52-313" aria-hidden="true" tabindex="-1"></a><span class="fu">sdf_persist</span>(ny_neighbourhoods_shp, <span class="at">storage.level =</span> <span class="st">"MEMORY_ONLY"</span>)</span>
<span id="cb52-314"><a href="#cb52-314" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-315"><a href="#cb52-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-316"><a href="#cb52-316" aria-hidden="true" tabindex="-1"></a>I have found that it is best to use **Spatial SQL** when conducting spatial joins or any other spatial analysis using Apache Sedona functions. To do this, we first need to register our dataframes as temporary **SQL views**. This will be our next step.</span>
<span id="cb52-317"><a href="#cb52-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-320"><a href="#cb52-320" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-321"><a href="#cb52-321" aria-hidden="true" tabindex="-1"></a><span class="co"># Register the dataframes as temporary SQL views for querying</span></span>
<span id="cb52-322"><a href="#cb52-322" aria-hidden="true" tabindex="-1"></a>locations_sdf <span class="sc">%&gt;%</span> <span class="fu">sdf_register</span>(<span class="st">"locations_sdf_view"</span>)</span>
<span id="cb52-323"><a href="#cb52-323" aria-hidden="true" tabindex="-1"></a>ny_neighbourhoods_shp <span class="sc">%&gt;%</span> <span class="fu">sdf_register</span>(<span class="st">"ny_neighbourhoods_shp_view"</span>)</span>
<span id="cb52-324"><a href="#cb52-324" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-325"><a href="#cb52-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-326"><a href="#cb52-326" aria-hidden="true" tabindex="-1"></a>Upon registration, we can now conduct a spatial join, asking Apache Sedona to find neighbourhoods that contain specific coordinates using the **ST_Contains** function. You can find documentation on all available Apache Sedona vector functions <span class="co">[</span><span class="ot">here</span><span class="co">](https://sedona.apache.org/latest/api/sql/Function/)</span>.</span>
<span id="cb52-327"><a href="#cb52-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-330"><a href="#cb52-330" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-331"><a href="#cb52-331" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a spatial join to associate each location (latitude, longitude) with the corresponding neighbourhood</span></span>
<span id="cb52-332"><a href="#cb52-332" aria-hidden="true" tabindex="-1"></a>locations_sdf_updated <span class="ot">&lt;-</span> <span class="fu">sdf_sql</span>(</span>
<span id="cb52-333"><a href="#cb52-333" aria-hidden="true" tabindex="-1"></a>  sc,</span>
<span id="cb52-334"><a href="#cb52-334" aria-hidden="true" tabindex="-1"></a>  <span class="st">"</span></span>
<span id="cb52-335"><a href="#cb52-335" aria-hidden="true" tabindex="-1"></a><span class="st">  SELECT /*+ BROADCAST(b) */ a.*, b.*</span></span>
<span id="cb52-336"><a href="#cb52-336" aria-hidden="true" tabindex="-1"></a><span class="st">  FROM locations_sdf_view a</span></span>
<span id="cb52-337"><a href="#cb52-337" aria-hidden="true" tabindex="-1"></a><span class="st">  LEFT JOIN ny_neighbourhoods_shp_view b</span></span>
<span id="cb52-338"><a href="#cb52-338" aria-hidden="true" tabindex="-1"></a><span class="st">    ON ST_Contains(b.geometry, ST_Point(a.longitude, a.latitude))</span></span>
<span id="cb52-339"><a href="#cb52-339" aria-hidden="true" tabindex="-1"></a><span class="st">  "</span></span>
<span id="cb52-340"><a href="#cb52-340" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb52-341"><a href="#cb52-341" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-342"><a href="#cb52-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-343"><a href="#cb52-343" aria-hidden="true" tabindex="-1"></a><span class="fu">## Writing data to disk</span></span>
<span id="cb52-344"><a href="#cb52-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-345"><a href="#cb52-345" aria-hidden="true" tabindex="-1"></a>Before saving our updated data, we remove the geometry column, as Delta Lake does not support geometry columns. Moreover, there is no need to keep it in the data, as we don't plan on mapping the data just yet. If you need to write big data geometry files, consider using the **GeoParquet** format. You can do so using Spark's <span class="in">`spark_write_geoparquet`</span> function or the <span class="in">`spark_write_source`</span> function with the mode set to "*geoparquet*".</span>
<span id="cb52-346"><a href="#cb52-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-349"><a href="#cb52-349" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-350"><a href="#cb52-350" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the geometry column from the final dataset for further analysis</span></span>
<span id="cb52-351"><a href="#cb52-351" aria-hidden="true" tabindex="-1"></a>locations_sdf_updated_no_geom <span class="ot">&lt;-</span> locations_sdf_updated <span class="sc">%&gt;%</span></span>
<span id="cb52-352"><a href="#cb52-352" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(geometry))</span>
<span id="cb52-353"><a href="#cb52-353" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-354"><a href="#cb52-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-355"><a href="#cb52-355" aria-hidden="true" tabindex="-1"></a>Our final data is as shown below. Not too bad for the few lines of code written.</span>
<span id="cb52-356"><a href="#cb52-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-359"><a href="#cb52-359" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-360"><a href="#cb52-360" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the updated data with all relevant fields (no geometry)</span></span>
<span id="cb52-361"><a href="#cb52-361" aria-hidden="true" tabindex="-1"></a>withr<span class="sc">::</span><span class="fu">with_options</span>(</span>
<span id="cb52-362"><a href="#cb52-362" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="at">pillar.sigfig =</span> <span class="dv">6</span>),</span>
<span id="cb52-363"><a href="#cb52-363" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(locations_sdf_updated_no_geom, <span class="at">n=</span><span class="dv">10</span>)</span>
<span id="cb52-364"><a href="#cb52-364" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb52-365"><a href="#cb52-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-366"><a href="#cb52-366" aria-hidden="true" tabindex="-1"></a>locations_sdf_updated_no_geom <span class="sc">%&gt;%</span> <span class="fu">glimpse</span>()</span>
<span id="cb52-367"><a href="#cb52-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-368"><a href="#cb52-368" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-369"><a href="#cb52-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-370"><a href="#cb52-370" aria-hidden="true" tabindex="-1"></a>We now write our data to Delta Lake format as usual.</span>
<span id="cb52-371"><a href="#cb52-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-374"><a href="#cb52-374" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-375"><a href="#cb52-375" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb52-376"><a href="#cb52-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-377"><a href="#cb52-377" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the file path for saving the updated dataset</span></span>
<span id="cb52-378"><a href="#cb52-378" aria-hidden="true" tabindex="-1"></a>save_locations_sdf_updated_one_filepath <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="fu">getwd</span>(), <span class="st">"data"</span>, <span class="st">"locations_sdf_updated_one"</span>)</span>
<span id="cb52-379"><a href="#cb52-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-380"><a href="#cb52-380" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the updated dataset to Delta format</span></span>
<span id="cb52-381"><a href="#cb52-381" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_write_delta</span>(</span>
<span id="cb52-382"><a href="#cb52-382" aria-hidden="true" tabindex="-1"></a>  locations_sdf_updated_no_geom,</span>
<span id="cb52-383"><a href="#cb52-383" aria-hidden="true" tabindex="-1"></a>  <span class="at">path =</span> save_locations_sdf_updated_one_filepath</span>
<span id="cb52-384"><a href="#cb52-384" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb52-385"><a href="#cb52-385" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-386"><a href="#cb52-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-387"><a href="#cb52-387" aria-hidden="true" tabindex="-1"></a>And disconnect our spark instance.</span>
<span id="cb52-388"><a href="#cb52-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-391"><a href="#cb52-391" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-392"><a href="#cb52-392" aria-hidden="true" tabindex="-1"></a><span class="co"># Disconnect from the Spark session once done</span></span>
<span id="cb52-393"><a href="#cb52-393" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_disconnect</span>(sc)</span>
<span id="cb52-394"><a href="#cb52-394" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/rog33zy/apache-sedona-r-tutorial.github.io/edit/main/preprocessing_two.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/rog33zy/apache-sedona-r-tutorial.github.io/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer><script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>